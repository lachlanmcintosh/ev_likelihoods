

# This file was *autogenerated* from the file everything.sage
from sage.all_cmdline import *   # import sage library

_sage_const_1 = Integer(1); _sage_const_2 = Integer(2); _sage_const_3 = Integer(3); _sage_const_4 = Integer(4); _sage_const_5 = Integer(5); _sage_const_100 = Integer(100); _sage_const_0 = Integer(0); _sage_const_200 = Integer(200)# precompute
import sys
import os

args = sys.argv
p_up = args[_sage_const_1 ]
p_down = args[_sage_const_2 ]
max_CN = args[_sage_const_3 ]
path_length = args[_sage_const_4 ]
path_description = args[_sage_const_5 ]


collated_output_file = "MATRICES/collated_u"+p_up+"_d"+p_down+"_"+path_description+".csv"
print("START")
print(collated_output_file)

import pickle
import numpy as np
from numpy import linalg as LA

if not os.path.isfile(collated_output_file):
  base_filename = "MATRICES/subbed_mat_u"+p_up+"_d"+p_down+"_"+path_description+".pickle"
  if not os.path.isfile(base_filename):
    m = load("MATRICES/matrix_"+path_description+".sobj")
    m2 = m.subs(u=int(p_up)/_sage_const_100 ,d=int(p_down)/_sage_const_100 )
    m2 = m2.apply_map(RR)
    m2 = m2.numpy(dtype='double')
    with open(base_filename, 'wb') as m_output:
      pickle.dump(m2, m_output)

  with open(base_filename,'rb') as m_data:
    m = pickle.load(m_data)


  if not os.path.isfile("GD.pickle"):
    # Create an empty matrix of zeros
    G = np.zeros((int(max_CN)+_sage_const_1 , int(max_CN)+_sage_const_1 ))

    # Fill in the appropriate entries with ones
    for i in range(round(int(max_CN)/_sage_const_2 )):
      G[i, _sage_const_2 *i] = _sage_const_1 

  else:
    with open("GD.pickle",'rb') as GD_data:
      G = pickle.load(GD_data)

  m = m[:(int(max_CN)+_sage_const_2 ),:(int(max_CN)+_sage_const_2 )]
  G = G[:(int(max_CN)+_sage_const_2 ),:(int(max_CN)+_sage_const_2 )]

  for row in range(int(max_CN)+_sage_const_1 ):
    total = sum(sum(m[row,:]))
    for col in range(int(max_CN)+_sage_const_1 ):
      if total != _sage_const_0 :
        m[row,col] = m[row,col]/total

  all_paths = load("all_path_combinations_"+path_description+".sobj")
  
  single_paths = [x for x in all_paths if "G" not in x]

  powers_filename = base_filename.split(".pickle")[_sage_const_0 ] + ".powers.pickle"
  if os.path.isfile(powers_filename):
    with open(powers_filename,'rb') as infile:
      powers = pickle.load(infile)
  else:
    powers = {}
  for path in single_paths:
    if int(path) not in powers:
      res = LA.matrix_power(m,int(path))
      powers[int(path)] = res
  with open(powers_filename,'wb') as infile:
    pickle.dump(powers,infile)

  precomputed_paths_filename = base_filename.split(".pickle")[_sage_const_0 ] + ".precomputed_paths.pickle"
  count = _sage_const_0 
  if os.path.isfile(precomputed_paths_filename):
    try:
      with open(precomputed_paths_filename,'rb') as precomputed_data:
        myd = pickle.load(precomputed_data)
    except:
      os.remove(precomputed_paths_filename)
      myd = {}
  else:
    myd = {}

  for path in all_paths:
    if path in myd:
      continue
    splits = path.split("G")
    G1 = _sage_const_0 
    G2 = _sage_const_0 
    if len(splits) == _sage_const_1 :
      pre = int(path)
      mid = _sage_const_0 
      post = _sage_const_0 
    if len(splits) == _sage_const_2 :
      pre = int(splits[_sage_const_0 ])
      mid = _sage_const_0 
      post = int(splits[_sage_const_1 ])
      G1 = _sage_const_1 
    if len(splits) == _sage_const_3 :
      pre = int(splits[_sage_const_0 ])
      mid = int(splits[_sage_const_1 ])
      post = int(splits[_sage_const_2 ])
      G1 = _sage_const_1 
      G2 = _sage_const_1 

    # compute the probabilities for this path:
    res = powers[pre] #LA.matrix_power(m,pre)
    
    if G1 > _sage_const_0 :
      res = np.matmul(res,G)

    res = np.matmul(res,powers[mid]) #LA.matrix_power(m,mid))

    if G2 > _sage_const_0 :
      res = np.matmul(res,G)

    res = np.matmul(res,powers[post]) #LA.matrix_power(m,post))


    myd[path] = res
    if count % _sage_const_200  == _sage_const_0 :
      with open(precomputed_paths_filename,'wb') as precomputed_data:
        pickle.dump(myd,precomputed_data)
    count = count + _sage_const_1 

  with open(precomputed_paths_filename,'wb') as precomputed_data:
    pickle.dump(myd,precomputed_data)

  # collate
  # iterate over all combinations of u and d and all paths and collate them into one data frame

  with open(precomputed_paths_filename, 'rb') as myd_data:
    myd = pickle.load(myd_data)

  out_text = ""

  for path in myd:
    m = myd[path]
    line = str(p_up)+","+str(p_down)
    line = line+","+path+","
    line = line+",".join([str(x) for x in m[_sage_const_1 ,:]])+"\n"
    out_text += line

  with open(collated_output_file,'w') as output_file:
    output_file.write(out_text)

